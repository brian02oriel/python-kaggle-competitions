{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-23T21:31:09.181221Z","iopub.status.busy":"2024-05-23T21:31:09.180030Z","iopub.status.idle":"2024-05-23T21:31:09.732913Z","shell.execute_reply":"2024-05-23T21:31:09.731453Z","shell.execute_reply.started":"2024-05-23T21:31:09.181152Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk(f'{os.getcwd()}/dataset'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-23T21:31:10.637197Z","iopub.status.busy":"2024-05-23T21:31:10.636543Z","iopub.status.idle":"2024-05-23T21:31:15.367706Z","shell.execute_reply":"2024-05-23T21:31:15.366521Z","shell.execute_reply.started":"2024-05-23T21:31:10.637160Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(\"./dataset/train.csv\")\n","test_df = pd.read_csv(\"./dataset/test.csv\")\n","train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-23T21:31:16.498080Z","iopub.status.busy":"2024-05-23T21:31:16.497177Z","iopub.status.idle":"2024-05-23T21:31:16.567980Z","shell.execute_reply":"2024-05-23T21:31:16.566712Z","shell.execute_reply.started":"2024-05-23T21:31:16.498043Z"},"trusted":true},"outputs":[],"source":["train_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-23T21:31:17.436640Z","iopub.status.busy":"2024-05-23T21:31:17.436219Z","iopub.status.idle":"2024-05-23T21:31:18.267841Z","shell.execute_reply":"2024-05-23T21:31:18.266495Z","shell.execute_reply.started":"2024-05-23T21:31:17.436607Z"},"trusted":true},"outputs":[],"source":["train_df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-23T21:31:19.338657Z","iopub.status.busy":"2024-05-23T21:31:19.337894Z","iopub.status.idle":"2024-05-23T21:31:19.346715Z","shell.execute_reply":"2024-05-23T21:31:19.345491Z","shell.execute_reply.started":"2024-05-23T21:31:19.338625Z"},"trusted":true},"outputs":[],"source":["train_df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-23T21:31:20.504631Z","iopub.status.busy":"2024-05-23T21:31:20.504161Z","iopub.status.idle":"2024-05-23T21:31:20.783593Z","shell.execute_reply":"2024-05-23T21:31:20.782160Z","shell.execute_reply.started":"2024-05-23T21:31:20.504597Z"},"trusted":true},"outputs":[],"source":["for col in train_df.columns:\n","    print(f'{col}: {train_df[col].unique()}')\n","    print(f'{col} min: {train_df[col].min()}')\n","    print(f'{col} max: {train_df[col].max()}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-23T21:31:21.733281Z","iopub.status.busy":"2024-05-23T21:31:21.732013Z","iopub.status.idle":"2024-05-23T21:31:22.096111Z","shell.execute_reply":"2024-05-23T21:31:22.093828Z","shell.execute_reply.started":"2024-05-23T21:31:21.733227Z"},"trusted":true},"outputs":[],"source":["train_df[train_df['FloodProbability'] > 0.5]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-23T21:31:22.975235Z","iopub.status.busy":"2024-05-23T21:31:22.974794Z","iopub.status.idle":"2024-05-23T21:31:28.965882Z","shell.execute_reply":"2024-05-23T21:31:28.964686Z","shell.execute_reply.started":"2024-05-23T21:31:22.975206Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline\n","# only in a Jupyter notebook\n","import matplotlib.pyplot as plt\n","train_df[train_df['FloodProbability'] > 0.5].hist(bins=50, figsize=(20,15))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-23T21:34:10.938413Z","iopub.status.busy":"2024-05-23T21:34:10.937972Z","iopub.status.idle":"2024-05-23T21:34:17.724812Z","shell.execute_reply":"2024-05-23T21:34:17.723391Z","shell.execute_reply.started":"2024-05-23T21:34:10.938379Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline\n","# only in a Jupyter notebook\n","import matplotlib.pyplot as plt\n","train_df.hist(bins=50, figsize=(20,15))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-23T21:34:22.658396Z","iopub.status.busy":"2024-05-23T21:34:22.657010Z","iopub.status.idle":"2024-05-23T21:34:34.077328Z","shell.execute_reply":"2024-05-23T21:34:34.075746Z","shell.execute_reply.started":"2024-05-23T21:34:22.658337Z"},"trusted":true},"outputs":[],"source":["from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","train_df_dr = train_df.copy()\n","train_df_dr = train_df_dr.drop(columns=['id'])\n","\n","# Apply PCA\n","pca = PCA(n_components=2)\n","principal_components = pca.fit_transform(train_df_dr)\n","\n","# Create a DataFrame with the principal components\n","pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n","\n","# Plot the principal components\n","plt.figure(figsize=(8, 6))\n","sns.scatterplot(x='PC1', y='PC2', data=pca_df)\n","plt.title('PCA - 2 Principal Components')\n","plt.xlabel('Principal Component 1')\n","plt.ylabel('Principal Component 2')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_groups(N):\n","    q = N // 3\n","    r = N % 3\n","    if r == 0:\n","        return q\n","    elif r >= 1:\n","        return q + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def grouping(col_df, N):\n","    return ['low' if i <= get_groups(N) else 'intermediate' if i <= get_groups(N) * 2 else 'high' for i in col_df]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import math\n","def get_features(df, is_train=True):\n","    new_df = df.copy()\n","    new_df['EnvironmentalStress'] =  new_df['Deforestation'] + new_df['Siltation'] + new_df['WetlandLoss']\n","    new_df['InfrastructureVulnerability'] =  new_df['DeterioratingInfrastructure'] + new_df['DrainageSystems'] + new_df['DamsQuality']\n","    new_df['DisasterRisk'] =  new_df['IneffectiveDisasterPreparedness'] + new_df['InadequatePlanning'] + new_df['PoliticalFactors']\n","    \n","    N_Urbanization = new_df['Urbanization'].max()\n","    new_df['UrbanizationGroup'] = grouping(new_df['Urbanization'], N_Urbanization)\n","    \n","    N_PopulationScore = new_df['PopulationScore'].max()\n","    new_df['PopulationScoreGroup'] = grouping(new_df['PopulationScore'], N_PopulationScore)\n","    \n","    N_MonsoonIntensity = new_df['MonsoonIntensity'].max()\n","    new_df['MonsoonIntensityGroup'] = grouping(new_df['MonsoonIntensity'], N_MonsoonIntensity)\n","    \n","    N_TopographyDrainage = new_df['TopographyDrainage'].max()\n","    new_df['TopographyDrainageGroup'] = grouping(new_df['TopographyDrainage'], N_TopographyDrainage)\n","    \n","    N_RiverManagement = new_df['RiverManagement'].max()\n","    new_df['RiverManagementGroup'] = grouping(new_df['RiverManagement'], N_RiverManagement)\n","\n","    N_Deforestation = new_df['Deforestation'].max()\n","    new_df['DeforestationGroup'] = grouping(new_df['Deforestation'], N_Deforestation)\n","\n","    N_DamsQuality = new_df['DamsQuality'].max()\n","    new_df['DamsQualityGroup'] = grouping(new_df['DamsQuality'], N_DamsQuality)\n","\n","    N_Siltation = new_df['Siltation'].max()\n","    new_df['SiltationGroup'] = grouping(new_df['Siltation'], N_Siltation)\n","\n","    N_IneffectiveDisasterPreparedness = new_df['IneffectiveDisasterPreparedness'].max()\n","    new_df['IneffectiveDisasterPreparednessGroup'] = grouping(new_df['IneffectiveDisasterPreparedness'], N_IneffectiveDisasterPreparedness)\n","\n","    N_DrainageSystems = new_df['DrainageSystems'].max()\n","    new_df['DrainageSystemsGroup'] = grouping(new_df['DrainageSystems'], N_DrainageSystems)\n","\n","    N_Landslides = new_df['Landslides'].max()\n","    new_df['LandslidesGroup'] = grouping(new_df['Landslides'], N_Landslides)\n","\n","    N_Watersheds = new_df['Watersheds'].max()\n","    new_df['WatershedsGroup'] = grouping(new_df['Watersheds'], N_Watersheds)\n","\n","    N_DeterioratingInfrastructure = new_df['DeterioratingInfrastructure'].max()\n","    new_df['DeterioratingInfrastructureGroup'] = grouping(new_df['DeterioratingInfrastructure'], N_DeterioratingInfrastructure)\n","\n","    N_WetlandLoss = new_df['WetlandLoss'].max()\n","    new_df['WetlandLossGroup'] = grouping(new_df['WetlandLoss'], N_WetlandLoss)\n","\n","    N_InadequatePlanning = new_df['InadequatePlanning'].max()\n","    new_df['InadequatePlanningGroup'] = grouping(new_df['InadequatePlanning'], N_InadequatePlanning)\n","\n","    N_PoliticalFactors = new_df['PoliticalFactors'].max()\n","    new_df['PoliticalFactorsGroup'] = grouping(new_df['PoliticalFactors'], N_PoliticalFactors)\n","\n","    N_ClimateChange = new_df['ClimateChange'].max()\n","    new_df['ClimateChangeGroup'] = grouping(new_df['ClimateChange'], N_ClimateChange)\n","    \n","    N_AgriculturalPractices = new_df['AgriculturalPractices'].max()\n","    new_df['AgriculturalPracticesGroup'] = grouping(new_df['AgriculturalPractices'], N_AgriculturalPractices)\n","    \n","    N_Encroachments = new_df['Encroachments'].max()\n","    new_df['EncroachmentsGroup'] = grouping(new_df['Encroachments'], N_Encroachments)\n","    \n","    N_CoastalVulnerability = new_df['CoastalVulnerability'].max()\n","    new_df['CoastalVulnerabilityGroup'] = grouping(new_df['CoastalVulnerability'], N_CoastalVulnerability)\n","    \n","    new_df['FloodRisk'] = 0.3 * new_df['MonsoonIntensity'] + 0.2 * new_df['TopographyDrainage'] + 0.5 * new_df['RiverManagement']\n","    new_df['EnvironmentalDegradation'] = 0.4 * new_df['Deforestation'] + 0.3 * new_df['Siltation'] + 0.3 * new_df['WetlandLoss']\n","\n","    if(is_train):\n","        # Move the Rings column to the last column place\n","        rings = new_df['FloodProbability']\n","        new_df = new_df.drop(columns=['FloodProbability'])\n","        new_df['FloodProbability'] = rings\n","    return new_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["new_train_df = get_features(train_df)\n","new_train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["new_train_df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def pie_chart(df, label):\n","    # Labels and counts\n","    counts = df.value_counts()\n","\n","    # Plotting the pie chart\n","    plt.figure(figsize=(5, 5))\n","    plt.pie(counts, labels=counts.index, autopct='%1.1f%%', colors=['#3487ff', '#73acff', '#a1c7ff'])\n","    plt.title(label)\n","    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pie_chart(new_train_df['UrbanizationGroup'], 'Urbanization Groups Distribution')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pie_chart(new_train_df['PopulationScoreGroup'], 'Population Score Groups Distribution')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pie_chart(new_train_df['MonsoonIntensityGroup'], 'Monsoon Intensity Groups Distribution')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def corr_matrix(cols):\n","    # Correlation matrix\n","    import seaborn as sns\n","    train_df_copy = new_train_df[cols].copy()\n","    corr_matrix = train_df_copy.corr()\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n","    plt.title('Correlation Matrix Heatmap')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["corr_matrix(['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n","       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n","       'Siltation', 'AgriculturalPractices', 'Encroachments', 'FloodProbability'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["corr_matrix(['IneffectiveDisasterPreparedness', 'DrainageSystems',\n","       'CoastalVulnerability', 'Landslides', 'Watersheds',\n","       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n","       'InadequatePlanning', 'PoliticalFactors', 'FloodProbability'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["corr_matrix(['EnvironmentalStress', 'InfrastructureVulnerability', 'DisasterRisk', 'FloodRisk', 'EnvironmentalDegradation', 'FloodProbability'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n","\n","def preprocessing(df, is_train=True):\n","\n","    numerical_features = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n","                           'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n","                           'Siltation', 'AgriculturalPractices', 'Encroachments',\n","                           'IneffectiveDisasterPreparedness', 'DrainageSystems',\n","                           'CoastalVulnerability', 'Landslides', 'Watersheds',\n","                           'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n","                           'InadequatePlanning', 'PoliticalFactors', 'EnvironmentalStress',\n","                           'InfrastructureVulnerability', 'DisasterRisk', 'FloodRisk', 'EnvironmentalDegradation']\n","    categorical_features = ['UrbanizationGroup','PopulationScoreGroup', 'MonsoonIntensityGroup',\n","                            'TopographyDrainageGroup', 'RiverManagementGroup', 'DeforestationGroup',\n","                            'DamsQualityGroup', 'SiltationGroup',\n","                            'IneffectiveDisasterPreparednessGroup', 'DrainageSystemsGroup',\n","                            'LandslidesGroup', 'WatershedsGroup',\n","                            'DeterioratingInfrastructureGroup', 'WetlandLossGroup',\n","                            'InadequatePlanningGroup', 'PoliticalFactorsGroup',\n","                            'ClimateChangeGroup', 'AgriculturalPracticesGroup',\n","                            'EncroachmentsGroup', 'CoastalVulnerabilityGroup']\n","    \n","    numerical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='mean')),\n","    ('scaler', StandardScaler())])\n","\n","    categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n","    \n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', numerical_transformer, numerical_features),\n","            ('cat', categorical_transformer, categorical_features)\n","        ])\n","    \n","    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n","    df_transformed = pipeline.fit_transform(df)\n","    \n","    columns_transformed = numerical_features + list(preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features))\n","    df_transformed = pd.DataFrame(df_transformed, columns=columns_transformed)\n","    \n","    df_transformed = pd.concat([pd.DataFrame(df[['id']], columns=['id']), df_transformed], axis=1) \n","    \n","    if(is_train):\n","        df_transformed = pd.concat([df_transformed, pd.DataFrame(df['FloodProbability'], columns=['FloodProbability']) ], axis=1) \n","        \n","    return df_transformed"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["processed_df = preprocessing(new_train_df)\n","processed_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["processed_df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_columns = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n","       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n","       'Siltation', 'AgriculturalPractices', 'Encroachments',\n","       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n","       'CoastalVulnerability', 'Landslides', 'Watersheds',\n","       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n","       'InadequatePlanning', 'PoliticalFactors', 'EnvironmentalStress',\n","       'InfrastructureVulnerability', 'DisasterRisk', 'FloodRisk',\n","       'EnvironmentalDegradation', 'UrbanizationGroup_high',\n","       'UrbanizationGroup_intermediate', 'UrbanizationGroup_low',\n","       'PopulationScoreGroup_high', 'PopulationScoreGroup_intermediate',\n","       'PopulationScoreGroup_low', 'MonsoonIntensityGroup_high',\n","       'MonsoonIntensityGroup_intermediate', 'MonsoonIntensityGroup_low',\n","       'TopographyDrainageGroup_high', 'TopographyDrainageGroup_intermediate',\n","       'TopographyDrainageGroup_low', 'RiverManagementGroup_high',\n","       'RiverManagementGroup_intermediate', 'RiverManagementGroup_low',\n","       'DeforestationGroup_high', 'DeforestationGroup_intermediate',\n","       'DeforestationGroup_low', 'DamsQualityGroup_high',\n","       'DamsQualityGroup_intermediate', 'DamsQualityGroup_low',\n","       'SiltationGroup_high', 'SiltationGroup_intermediate',\n","       'SiltationGroup_low', 'IneffectiveDisasterPreparednessGroup_high',\n","       'IneffectiveDisasterPreparednessGroup_intermediate',\n","       'IneffectiveDisasterPreparednessGroup_low', 'DrainageSystemsGroup_high',\n","       'DrainageSystemsGroup_intermediate', 'DrainageSystemsGroup_low',\n","       'LandslidesGroup_high', 'LandslidesGroup_intermediate',\n","       'LandslidesGroup_low', 'WatershedsGroup_high',\n","       'WatershedsGroup_intermediate', 'WatershedsGroup_low',\n","       'DeterioratingInfrastructureGroup_high',\n","       'DeterioratingInfrastructureGroup_intermediate',\n","       'DeterioratingInfrastructureGroup_low', 'WetlandLossGroup_high',\n","       'WetlandLossGroup_intermediate', 'WetlandLossGroup_low',\n","       'InadequatePlanningGroup_high', 'InadequatePlanningGroup_intermediate',\n","       'InadequatePlanningGroup_low', 'PoliticalFactorsGroup_high',\n","       'PoliticalFactorsGroup_intermediate', 'PoliticalFactorsGroup_low',\n","       'ClimateChangeGroup_high', 'ClimateChangeGroup_intermediate',\n","       'ClimateChangeGroup_low', 'AgriculturalPracticesGroup_high',\n","       'AgriculturalPracticesGroup_intermediate',\n","       'AgriculturalPracticesGroup_low', 'EncroachmentsGroup_high',\n","       'EncroachmentsGroup_intermediate', 'EncroachmentsGroup_low',\n","       'CoastalVulnerabilityGroup_high',\n","       'CoastalVulnerabilityGroup_intermediate',\n","       'CoastalVulnerabilityGroup_low']\n","y_columns = ['FloodProbability']\n","X = processed_df[X_columns]\n","y = processed_df[y_columns]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","def findBestParams(model, params, X, y):\n","    grid_search = GridSearchCV(model, params, cv=5, scoring='r2', verbose=10)\n","\n","    # Fit the GridSearchCV object to the data\n","    grid_search.fit(X, y.values.ravel())\n","\n","    # Get the best parameters and best model\n","    best_params = grid_search.best_params_\n","    best_model = grid_search.best_estimator_\n","\n","    # Display the results\n","    print(\"Best Hyperparameters:\", best_params)\n","    return best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.linear_model import Lasso\n","\n","# Define the parameter grid for GridSearch\n","param_grid = {\n","    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n","}\n","lasso_model = findBestParams(Lasso(), param_grid, X_train, y_train)\n","lasso_model.fit(X_train, y_train.values.ravel())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["lasso_model_pred = lasso_model.predict(X_test)\n","lasso_model_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import r2_score\n","\n","def get_metrics(y_pred, y_true):\n","    r2_score_value = r2_score(y_true, y_pred)\n","    print(f\"r2 score: {r2_score_value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["get_metrics(lasso_model_pred, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.linear_model import Ridge\n","\n","# Define the parameter grid for GridSearch\n","param_grid = {\n","    'alpha': [0.001, 0.01, 0.1, 1, 10],\n","}\n","ridge_model = findBestParams(Ridge(), param_grid, X_train, y_train)\n","ridge_model.fit(X_train, y_train.values.ravel())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ridge_pred = ridge_model.predict(X_test)\n","ridge_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["get_metrics(ridge_pred, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import BayesianRidge\n","\n","# Define the parameter grid for GridSearch\n","param_grid = {\n","    'n_iter': [300, 500, 1000],\n","    'alpha_1': [1e-6, 1e-5, 1e-4],\n","    'alpha_2': [1e-6, 1e-5, 1e-4],\n","}\n","bayesian_ridge_model = findBestParams(BayesianRidge(), param_grid, X_train, y_train)\n","bayesian_ridge_model.fit(X_train, y_train.values.ravel())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bayesian_ridge_pred = bayesian_ridge_model.predict(X_test)\n","bayesian_ridge_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["get_metrics(bayesian_ridge_pred, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_df = get_features(test_df, False)\n","test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_processed_df = preprocessing(test_df, False)\n","test_processed_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_submission(y_pred, id_column, target_cols, filename):\n","    df = pd.DataFrame(data=y_pred, columns=target_cols)\n","    df[\"id\"] = id_column\n","    df = df[['id', 'FloodProbability']]\n","    df.to_csv('./submission/'+filename+'.csv', index=False)\n","    print(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["lasso_pred = lasso_model.predict(test_processed_df[X_columns])\n","lasso_pred = [abs(x) for x in lasso_pred]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ridge_pred = ridge_model.predict(test_processed_df[X_columns])\n","ridge_pred = [abs(x) for x in ridge_pred]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["get_submission(lasso_pred, test_processed_df[\"id\"], [\"FloodProbability\"], \"lasso_pred\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["get_submission(ridge_pred, test_processed_df[\"id\"], [\"FloodProbability\"], \"ridge_pred\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8121328,"sourceId":73278,"sourceType":"competition"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
